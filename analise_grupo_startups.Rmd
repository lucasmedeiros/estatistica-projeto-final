---
title: "Análise do modelo das Startups"
author: "Jadson Luan, Jessé Souza e Lucas Medeiros"
date: "1 de julho de 2019"
output: 
  html_document:
    code_folding: "hide"
    toc: yes
    toc_depth: 5
    toc_float:
      collapsed: no
    df_print: paged
---

```{r setup, include=FALSE}
library(tidyverse)
library(stats)
library(caTools)
library(car)
library(MASS)

startup_dataset <- read_csv(here::here("data/50_startups.csv"),
                 col_types = "dddcd")

names(startup_dataset)[names(startup_dataset) == 'ReD'] <- 'PeD'
names(startup_dataset)[names(startup_dataset) == 'Administration'] <- 'Administracao'
names(startup_dataset)[names(startup_dataset) == 'State'] <- 'Estado'
names(startup_dataset)[names(startup_dataset) == 'Profit'] <- 'Lucro'

set.seed(100)

split = sample.split(startup_dataset$Lucro, SplitRatio = 0.8)

startup_training_set = subset(startup_dataset, split == TRUE)
startup_test_set = subset(startup_dataset, split == FALSE)
```

## Caso do grupo das startups

Vamos fazer uma análise com mais abordagens de seleção de modelo a partir dos dados do grupo com a temática "*Quais gastos interferem no lucro de uma startup?*".

**OBS: para todos os casos, utilizaremos nível de significância de 5%**.

### Backward Elimination

Inicaremos pelo caso mostrado pelo grupo, o "Backward Elimination", que tem os seguintes passos:

1) Define-se o nível de significância;
2) Ajusta-se o modelo com todas as variáveis independentes possíveis;
3) Considera-se a variável com maior valor-p;
4) Se o valor p é maior que o nível de significância, remove-se a variável; 
5) Ajusta-se novamente o modelo, agora sem a variável removida.

```{r}
fit1 <- lm(Lucro ~ ., startup_training_set)
fit2 <- lm(Lucro ~ 1, startup_training_set)

stepAIC(fit1,direction="backward")
```

**Conclusão**: pela abordagem da **Backward Elimination**, chegamos ao modelo ideal apenas com as variáveis **PeD** e **Marketing**.

### Forward Elimination

Agora, utilizaremos a abordagem "Forward Elimination" para verificar se esta diz que o mesmo modelo é o ideal. Esse método possui os seguintes passos:

1) Define-se o nível de significância;
2) Parte-se da suposição de que não há variável no modelo, apenas o intercepto;
3) Adiciona-se uma variável de cada vez ao modelo, usando como critério a maior correlação para a menor.

```{r}
stepAIC(fit2,direction="both",scope=list(upper=fit1,lower=fit2))
```

**Conclusão**: pela abordagem da **Forward Elimination**, também chegamos ao modelo ideal apenas com as variáveis **PeD** e **Marketing**, assim como foi na **Backward Elimination**.

### Stepwise

Agora, para finalizar, vamos utilizar a abordagem **Stepwise** para seleção do melhor modelo e verificar se ela também diz que o modelo definido pelas duas abordagens anteriores é o mesmo. Veja abaixo a aplicação do método:

```{r}
stepAIC(fit2,direction="both",scope=list(upper=fit1,lower=fit2))
```

Como podemos observar, a partir do método *stepwise*, percebemos que a seleção do modelo ideal para representação dos dados foi o que contém **PeD** e **Marketing**, assim como nas duas abordagens anteriores.

**Conclusão**: pelas três abordagens escolhidas para selecionar o modelo, podemos definir que o melhor modelo é o que contém **PeD** e **Marketing**.